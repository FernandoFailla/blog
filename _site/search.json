[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fernando F. Foschiani",
    "section": "",
    "text": "Curioso e feliz, com uma bela namorada e um pc gamer."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Fernando F. Foschiani",
    "section": "Education",
    "text": "Education\nCiÃªncias Atuariais - UNIFESP| Osasco | Mar 2019 - Dez 2023"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Fernando F. Foschiani",
    "section": "Experience",
    "text": "Experience\nLexis Nexis Risk Solutions | Data Scientist II | Mai 2024 - o momento\nBradesco Seguros | Cientista de Dados Junior | Ago 2022 - Mai 2024\nBradesco | Estagiario | Mar 2021 - Ago 2022"
  },
  {
    "objectID": "blog/third-post/index.html",
    "href": "blog/third-post/index.html",
    "title": "Third Blog Post",
    "section": "",
    "text": "The source for any page in your website could also be a Jupyter Notebook. This one is third-post/index.ipynb.\nHereâ€™s an example I borrowed from the Seaborn docs:\n\nimport seaborn as sns\n\nsns.set_theme(style=\"whitegrid\")\n\n# Load the diamonds dataset\ndiamonds = sns.load_dataset(\"diamonds\")\n\n# Plot the distribution of clarity ratings, conditional on carat\nsns.displot(\n    data=diamonds,\n    x=\"carat\", hue=\"cut\",\n    kind=\"kde\", height=4, aspect=1.5,\n    multiple=\"fill\", clip=(0, None),\n    palette=\"ch:rot=-.25,hue=1,light=.75\",   \n)"
  },
  {
    "objectID": "blog/second-post/index.html",
    "href": "blog/second-post/index.html",
    "title": "Second Post",
    "section": "",
    "text": "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua.\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Quis imperdiet massa tincidunt nunc pulvinar sapien et ligula. Amet cursus sit amet dictum sit amet. Eget duis at tellus at urna condimentum. Convallis aenean et tortor at risus viverra. Tincidunt ornare massa eget egestas purus viverra accumsan. Et malesuada fames ac turpis egestas. At imperdiet dui accumsan sit amet. Ut ornare lectus sit amet est placerat. Enim nulla aliquet porttitor lacus luctus accumsan tortor posuere. Duis ultricies lacus sed turpis tincidunt id aliquet risus. Mattis enim ut tellus elementum sagittis. Dui id ornare arcu odio ut. Natoque penatibus et magnis dis. Libero justo laoreet sit amet cursus sit. Sed faucibus turpis in eu. Tempus iaculis urna id volutpat lacus laoreet.\nPhasellus vestibulum lorem sed risus. Eget felis eget nunc lobortis mattis. Sit amet aliquam id diam maecenas ultricies. Egestas maecenas pharetra convallis posuere morbi. Etiam erat velit scelerisque in dictum non consectetur a erat. Cras fermentum odio eu feugiat pretium nibh ipsum consequat. Viverra accumsan in nisl nisi scelerisque. Et netus et malesuada fames ac. Amet tellus cras adipiscing enim eu turpis egestas pretium aenean. Eget lorem dolor sed viverra ipsum nunc aliquet. Ultrices dui sapien eget mi proin sed libero enim sed. Ultricies mi eget mauris pharetra et ultrices neque. Ipsum suspendisse ultrices gravida dictum. A arcu cursus vitae congue mauris rhoncus aenean vel. Gravida arcu ac tortor dignissim convallis. Nulla posuere sollicitudin aliquam ultrices."
  },
  {
    "objectID": "blog/first-post/index.html",
    "href": "blog/first-post/index.html",
    "title": "First Post",
    "section": "",
    "text": "Sed risus ultricies tristique nulla aliquet. Neque volutpat ac tincidunt vitae semper quis lectus nulla.\nLorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Enim sed faucibus turpis in eu mi bibendum neque. Ac orci phasellus egestas tellus rutrum tellus pellentesque eu. Velit sed ullamcorper morbi tincidunt ornare massa. Sagittis id consectetur purus ut faucibus pulvinar elementum integer. Tincidunt nunc pulvinar sapien et ligula ullamcorper malesuada proin libero. Lobortis feugiat vivamus at augue eget arcu. Aliquam ut porttitor leo a diam sollicitudin tempor id eu. Mauris a diam maecenas sed enim ut sem viverra aliquet. Enim ut tellus elementum sagittis vitae et leo duis. Molestie at elementum eu facilisis sed odio morbi quis commodo. Sapien pellentesque habitant morbi tristique senectus. Quam vulputate dignissim suspendisse in est. Nulla pellentesque dignissim enim sit amet venenatis urna cursus eget.\nVelit aliquet sagittis id consectetur purus ut faucibus pulvinar elementum. Viverra mauris in aliquam sem fringilla ut morbi tincidunt augue. Tortor at auctor urna nunc id. Sit amet consectetur adipiscing elit duis tristique sollicitudin. Aliquet nibh praesent tristique magna sit amet purus. Tristique senectus et netus et malesuada fames ac turpis. Hac habitasse platea dictumst quisque. Auctor neque vitae tempus quam pellentesque nec nam aliquam. Ultrices tincidunt arcu non sodales neque sodales ut etiam. Iaculis at erat pellentesque adipiscing. Cras tincidunt lobortis feugiat vivamus. Nisi est sit amet facilisis magna etiam. Pharetra pharetra massa massa ultricies mi quis hendrerit. Vitae sapien pellentesque habitant morbi tristique senectus. Ornare aenean euismod elementum nisi quis eleifend quam adipiscing vitae."
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Projects",
    "section": "",
    "text": "Predicting House Prices with Machine Learning\n\n\n\nPython\n\n\nMachine Learning\n\n\nData Cleaning\n\n\n\nThis project involves using machine learning algorithms to predict house prices based on various features such as location, size, and amenities. It includes data cleaning, feature engineering, and model selection.\n\n\n\nJan 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCustomer Segmentation Using Clustering Techniques\n\n\n\nR\n\n\nMachine Learning\n\n\nClustering\n\n\nStatistical Modelling\n\n\n\nThis project focuses on segmenting customers into different groups based on their purchasing behavior and demographics. It uses clustering algorithms like K-means and hierarchical clustering to identify distinct customer segments.\n\n\n\nApr 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizing Global CO2 Emissions\n\n\n\nR\n\n\nData Visualization\n\n\nEnvironmental Science\n\n\n\nThis project involves creating visualizations to show trends in global CO2 emissions over time. It includes data extraction from public databases, data cleaning, and using visualization libraries to create interactive charts and graphs.\n\n\n\nJul 1, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/teste.html",
    "href": "blog/teste.html",
    "title": "Teste",
    "section": "",
    "text": "Curioso e feliz, com uma BELA NAMORADA e um PC GAMER."
  },
  {
    "objectID": "blog/teste.html#teste",
    "href": "blog/teste.html#teste",
    "title": "Teste",
    "section": "",
    "text": "Curioso e feliz, com uma BELA NAMORADA e um PC GAMER."
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "Como inserir dados no DuckDB com R?\n\n\n\n\n\n\n\n\n\n\n\nNov 24, 2024\n\n\nFernando F. Foschiani\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/InserindoDadosDuckDb/index.html",
    "href": "blog/InserindoDadosDuckDb/index.html",
    "title": "Como inserir dados no DuckDB com R?",
    "section": "",
    "text": "Note\n\n\n\nEsse post faz parte de uma serie de posts sobre Regressao Linear em Big Data. O post principal pode ser encontrado aqui.\nUm ponto bem importante para comecar a responder o tema desse post, e na realidade, bem intuitivo, precisamos de uma base de dados que JUSTIFIQUEM o DuckDB.\nE acredito que se voce chegou por aqui, voce deve estar de olhos nas principais habilidades do PatoDB:\nEntao inicialmente, caso sua base de dados seja pequena, e voce nao ira realizar operacoes intensivas de analise dados, talvez voce possa simplificar o seu workflow ao nao utilizar o DuckDB.\nMas como aqui, estamos para uma demonstracao, irei orgulhar os professores de analise de dados da UNIFESP, e extender o uso de uma base que ja colocou os incriveis notebook de 4gb de RAM de toda a turma para chorar no projeto de conclusao da materia. Os microdados do ENEM."
  },
  {
    "objectID": "blog/InserindoDadosDuckDb/index.html#prepare-a-internet",
    "href": "blog/InserindoDadosDuckDb/index.html#prepare-a-internet",
    "title": "Como inserir dados no DuckDB com R?",
    "section": "Prepare a Internet !!!",
    "text": "Prepare a Internet !!!\nOs microdados do ENEM sao bases de dados fornecidos Ministerio da Saude, e sao o menor nivel de desagregacao de dados recolhido pelo exame, ou seja, sao meio pesadinhos, tendo em media a base de cada ano uns 2GB.Lembro que durante meu curso de ciencias atuarias, muitos alunos nao conseguiram carregar um unico ano na memoria de seus notebooks, e tiveram que recorrer a utilizarem os computadores da universidade. Mas eu estou aqui para valorizar todos os PCs da xuxa, e botar todo hardware para brilhar com o DuckDB.\nEntao, para comecar quebrando tudo, vamos baixar a base de dados do ENEM dos ultimos 5 anos, que pode ser encontrada aqui.\nPara isso vamos criar uma funcao bem simples para baixar os arquivos, e depois descompacta-los, e se sua Internet for da Claro igual a minha, voce vai ter que aumentar o tempo de espera ate dar timeout do download.\n\noptions(timeout = 1200)\n\ndownload_enem &lt;- function(years){\n  # Cria diretorios se nao existirem\n  dir.create(\"data\", showWarnings = FALSE)\n  dir.create(\"data/raw\", showWarnings = FALSE)\n  dir.create(\"data/unzip\", showWarnings = FALSE)\n\n  existing_files &lt;- list.files(\"data/raw\")\n  if(length(existing_files) &gt; 0) {\n    warning(\"Arquivos jÃ¡ existem na pasta data/raw\")\n    print(existing_files)\n    return(NULL)\n  }\n\n  # Baixa os arquivos\n  for(year in years){\n    url &lt;- paste0(\n      \"https://download.inep.gov.br/microdados/microdados_enem_\",\n      year, \".zip\"\n    )\n    download.file(url, destfile = paste0(\"data/raw/microdados_enem_\", year, \".zip\"))\n    unzip(paste0(\"data/raw/microdados_enem_\", year, \".zip\"), \n          exdir = \"data/unzip\")\n  }\n}\n\nAgora vamos baixar os arquivos dos ultimos 5 anos.\n\ndownload_enem(2019:2023)\n\nPodemos, entao, verificar se os arquivos foram baixados corretamente.\n\nlist.files(\"data/unzip/DADOS\")\n\n [1] \"ITENS_PROVA_2019.csv\"     \"ITENS_PROVA_2020.csv\"    \n [3] \"ITENS_PROVA_2021.csv\"     \"ITENS_PROVA_2022.csv\"    \n [5] \"ITENS_PROVA_2023.csv\"     \"MICRODADOS_ENEM_2019.csv\"\n [7] \"MICRODADOS_ENEM_2020.csv\" \"MICRODADOS_ENEM_2021.csv\"\n [9] \"MICRODADOS_ENEM_2022.csv\" \"MICRODADOS_ENEM_2023.csv\"\n[11] \"QUEST_HAB_ESTUDO.csv\"    \n\n\nOs dados que estamos interessados sao os arquivos MICRODADOS_ENEM_*.csv, podemos entao selecionar apenas esses arquivos em uma variavel para utilizarmos na etapa de ingestao do DuckDB.\n\n# Parametro pattern para utilizar regex para selecao de arquivos\n# Parametro full.names para retornar o caminho completo do arquivo\nmicrodados_enem &lt;- list.files(\n  \"data/unzip/DADOS\",\n  pattern = \"MICRODADOS_ENEM_.*.csv\",\n  full.names = TRUE\n)\nmicrodados_enem\n\n[1] \"data/unzip/DADOS/MICRODADOS_ENEM_2019.csv\"\n[2] \"data/unzip/DADOS/MICRODADOS_ENEM_2020.csv\"\n[3] \"data/unzip/DADOS/MICRODADOS_ENEM_2021.csv\"\n[4] \"data/unzip/DADOS/MICRODADOS_ENEM_2022.csv\"\n[5] \"data/unzip/DADOS/MICRODADOS_ENEM_2023.csv\""
  },
  {
    "objectID": "blog/InserindoDadosDuckDb/index.html#agora-comeca-a-diversao",
    "href": "blog/InserindoDadosDuckDb/index.html#agora-comeca-a-diversao",
    "title": "Como inserir dados no DuckDB com R?",
    "section": "Agora comeca a diversao ðŸ˜ƒ",
    "text": "Agora comeca a diversao ðŸ˜ƒ\nBom, eu menti,antes de comecar realmente a diversao, e mostrar o passo a passo de como exatamente fazer esse caso especifico, gostaria de passar algumas referencias que vieram do meu looping infinito de acompanhar linkedin e ver tutoriais do youtube.\nAs duas principais ferramentas dessa etapa exatamente, sao o Arrow e o DuckDB,que interagem com o R atraves de bibliotecas com o mesmo nome. Outro pacote importante e o DBI, responsavel por ajudar o R a ser conectar com diferntes DBMS (Data Base Management Systems).\n\nO livro R for Data Science (2e), apresenta no capitulo 21 como interagir com banco de dados atraves do DBI, e no capitulo 22 como utilizar arrow para lidar com volumes de dados maiores do que a memoria. Em ambos, apresenta um pouco sobre como DuckDB pode ser utilizado nestes workflows.\nUm palestra introdutoria dada pela Nic Crane e Steph Hazlitt, bem completo e com bastantes exemplos hands-on para quem prefere uma abordagem mais em video. A propria Nic Crane,disponibiliza um livro sobre como Escalar R com Arrow, eu particularmente nao dei muito mais do que uma folheada, mas parece ter sido feito com bastante empenho e carinho.\nEu particularmente nao tenho muitas referencias mais aprofundadas sobre o duckdb em R, mas eu gosto bastante das apresentacoes do Hannes MuÌˆhleisen, especial sua apresentacao na posit::conf(2023) que serve como uma otima introducao, e sua ultima apresentacao na posit::conf(2024) com um aprofundamento mais teorico, e introduz alguns novos conceitos interessantes como arquivos .duckdb . Ultima recomendacao em relacao ao DuckDB, que remete as escolhas feitas por essa publicacao e um post feito por Josiah Parry comparando {duckdb} vs.Â {duckplyr}, esse post explica os motivos por eu nunca optar pela utilizacao do duckplyr para analises de grandes conjuntos de dados.\n\nNenhuma dessas referencias sao necessarias para continuuar a leitura desse post, mas sao otimas para quem quiser ir alem do caso em especifico que irei mostrar."
  },
  {
    "objectID": "blog/InserindoDadosDuckDb/index.html#agora-sim-a-diversao",
    "href": "blog/InserindoDadosDuckDb/index.html#agora-sim-a-diversao",
    "title": "Como inserir dados no DuckDB com R?",
    "section": "Agora sim: A DIVERSAO ðŸŽŠ",
    "text": "Agora sim: A DIVERSAO ðŸŽŠ\nPara ler todos os arquivos dentro do R, vamos utilizar o pacote arrow, que nos permite ler arquivos CSV e transforma-los em um objeto arrow::Table.\n\nlibrary(arrow)\n\n\nAttaching package: 'arrow'\n\n\nThe following object is masked from 'package:utils':\n\n    timestamp\n\ndf &lt;- arrow::open_dataset(\n  microdados_enem,\n  col_types = schema(ISBN = string()),\n  format = \"csv\",\n  delimiter = \";\"\n)"
  }
]